{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Timelines of Users\n",
    "\n",
    "This script is used to download the latest tweets of a set of specified users and then save the tweet IDs and dates/times to .txt files for later use. It uses Twitter's [GET statuses/user_timeline REST API](https://developer.twitter.com/en/docs/tweets/timelines/api-reference/get-statuses-user_timeline).\n",
    "\n",
    "In this case, I'm using it to download the latest tweets of four news sources: Mother Jones, Rabble, Breitbart, and Rebel News.\n",
    "\n",
    "#### Rate Limits\n",
    "\n",
    "For GET statuses/user_timeline, the rate limits are as follows:\n",
    "* 900 requests every 15 minutes\n",
    "* 100,000 requests every 24 hours\n",
    "\n",
    "As you can attempt to download up to 3,200 tweets from each user, this would mean each user costs you 16 requests. This means you are permitted to download the timelines of:\n",
    "* 56 users every 15 minutes\n",
    "* 6,250 users every 24 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy as tw\n",
    "from tweepy import OAuthHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Gaining Access\n",
    "\n",
    "Second, I have to list my user credentials to access the Twitter API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = 'ACCESS TOKEN'\n",
    "access_token_secret = 'SECRET ACCESS TOKEN'\n",
    "consumer_key = 'CONSUMER KEY'\n",
    "consumer_secret = 'SECRET CONSUMER KEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, I have to provide the keys and tokens to Twitter as part of the authorization process and, then, create the actual interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tw.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Functions\n",
    "\n",
    "Next, I define the necessary functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below returns a specified user's timeline and returns it as a dictionary where each item within it is another dictionary representing each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeline(username):\n",
    "    nested_dict = {}\n",
    "    num_dict = 1\n",
    "    results = tw.Cursor(api.user_timeline, screen_name=username, tweet_mode=\"extended\", include_rts = False).items()\n",
    "    for status in results:\n",
    "        nested_dict[num_dict] = status._json\n",
    "        num_dict += 1\n",
    "    return(nested_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below is used to name the .json file to which the timeline will be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_json(username):\n",
    "    \n",
    "    document_name = str(\"/Users/kateschneider/Documents/U of T 2019-2020/COVID-19 Research Project/News Source Timelines/\" + username + \"_timeline.json\")\n",
    "    return(document_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Specifying Users\n",
    "\n",
    "List the users for downloading their timelines (latest tweets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usernames = ['MotherJones', 'rabbleca', 'BreitbartNews', 'RebelNewsOnline']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Printing to JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in usernames:\n",
    "    try: \n",
    "        tweets = timeline(user)\n",
    "        with open(name_json(user), 'w', encoding='utf8') as f:\n",
    "            json.dump(tweets, f)\n",
    "    except TweepError:\n",
    "        print('Error! Failed to complete request.')\n",
    "        print(TweepError.response.status_code)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Pulling Tweet IDs\n",
    "Pulling all the IDs of the latest 3,200 tweets and saving them to a .txt file for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = 'RebelNewsOnline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(name_json(handle), 'r') as g:\n",
    "    datastore = json.load(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below prints all tweet IDs and dates as a list to .txt files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 1\n",
    "id_list = []\n",
    "date_list = []\n",
    "id_document_name = str(\"/Users/kateschneider/Documents/U of T 2019-2020/COVID-19 Research Project/News Source Tweet IDs/\" + handle + \"_tweet_ids.txt\")\n",
    "date_document_name = str(\"/Users/kateschneider/Documents/U of T 2019-2020/COVID-19 Research Project/News Source Tweet IDs/\" + handle + \"_tweet_dates.txt\")\n",
    "\n",
    "while num < 3201:\n",
    "    try: \n",
    "        id_list.append(datastore[str(num)]['id'])\n",
    "        date_list.append(datastore[str(num)]['created_at'])\n",
    "    except KeyError:\n",
    "        print(\"Finished printing tweet IDs and dates. Total tweet IDs collected is \" + str(num - 1))\n",
    "        break\n",
    "    num += 1\n",
    "\n",
    "if num == 3200:\n",
    "    print(\"Finished printing tweet IDs and dates. Total tweet IDs collected is \" + str(num - 1)\n",
    "\n",
    "print(\"Next, saving tweet IDs and tweet dates to .txt files\")    \n",
    "with open(id_document_name, 'w') as f:\n",
    "    f.write(str(id_list))\n",
    "print(\"Finished saving tweet IDs.\")    \n",
    "with open(date_document_name, 'w') as f:\n",
    "    f.write(str(date_list))\n",
    "print(\"Finished saving tweet dates.\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the cell below to find out the earliest and latest dates/times for tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datastore['1']['created_at'])\n",
    "print(datastore['3210']['created_at'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
