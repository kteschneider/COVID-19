{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Latest Retweets Using Tweet ID\n",
    "\n",
    "This script is used to download the latest retweets of a set of specified tweets using their IDs. It uses Twitter's [GET statuses/retweets/:id REST API](https://developer.twitter.com/en/docs/tweets/post-and-engage/api-reference/get-statuses-retweets-id).\n",
    "\n",
    "In this case, I'm using it to download the latest retweets of tweets from four news sources: Mother Jones, Rabble, Breitbart, and Rebel News.\n",
    "\n",
    "#### Rate Limits\n",
    "\n",
    "For GET statuses/retweets/:id, the rate limits are as follows:\n",
    "* 75 requests every 15 minutes\n",
    "* No 24 hour limit\n",
    "\n",
    "As each request is 100 tweets, this means you are permitted to download 7500 tweets every 15 minutes.\n",
    "\n",
    "#### Tweepy Documentation\n",
    "\n",
    "For Tweepy's documentation on GET statuses/retweets/:id, see [here](http://docs.tweepy.org/en/latest/api.html#API.retweets). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy as tw\n",
    "from tweepy import OAuthHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Gaining Access\n",
    "\n",
    "Second, I have to list my user credentials to access the Twitter API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access_token = [ACCESS TOKEN HERE]\n",
    "# access_token_secret = [SECRET ACCESS TOKEN HERE]\n",
    "# consumer_key = [CONSUMER KEY HERE]\n",
    "# consumer_secret = [SECRET CONSUMER KEY HERE]\n",
    "\n",
    "access_token = '1149713584349470726-Jhg4lRPDr4KhQvTptLzln95EXJbvjp'\n",
    "access_token_secret = 'kPbL8n2wqZJ467ci8F3UJfkPGSN56qqyFfu9xFq16UPnI'\n",
    "consumer_key = 'fgLl7cExe3Wi3ufYPtqCsmtse'\n",
    "consumer_secret = 'Q0wsv6CJ12gLjq9Gw3aq6eL259HWG9dOGuPe46xM4K60WIXPgR'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, I have to provide the keys and tokens to Twitter as part of the authorization process and, then, create the actual interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tw.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Functions\n",
    "\n",
    "Next, I define the necessary functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below returns the 100 latest retweets of a tweet (specified using its tweet id) and returns it as a dictionary where each item within it is another dictionary representing each retweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retweets(tweet_id):\n",
    "    nested_dict = {}\n",
    "    num_dict = 1\n",
    "    results = api.retweets(id=tweet_id, count=100)\n",
    "    for status in results:\n",
    "        nested_dict[num_dict] = status._json\n",
    "        num_dict += 1\n",
    "    return(nested_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below pulls the list of tweet IDs from the relevant .txt document and evaluates it as a Python expression (i.e. reads it properly as a list instead of as a string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(document):\n",
    "    with open(document, 'r') as f:\n",
    "        data = ast.literal_eval(f.read())\n",
    "    f.close()\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below is used to name the .json file to which the retweets will be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_json(username):\n",
    "    document_name = str(username + \"_retweets.json\")\n",
    "    return(document_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Driver Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I load the list of tweet IDs from the relevant .txt document as id_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completing 75 tweets out of 1714\n"
     ]
    }
   ],
   "source": [
    "username = 'RebelNewsOnline' # this can be changed between each of the four news sources\n",
    "document = str(username + \"_tweet_ids.txt\") #no need to change this line\n",
    "\n",
    "temp_list = read_file(document)\n",
    "id_list = temp_list[0:75]\n",
    "print(\"Completing\", len(id_list), \"tweets out of\", len(temp_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first create an empty dictionary, master_tweet_dict. This will contain *all* of the retweets of *all* tweets. Therefore, this will contain 100 retweets multiplied by the number of tweets collected per news source (something under 3,200). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just finished collecting the retweets of 75 original tweets. Going to pause for 15 minutes.\n",
      "Paused for 5 minutes so far. 10 minutes remaining.\n"
     ]
    }
   ],
   "source": [
    "master_tweet_dict = {}\n",
    "master_num = 1\n",
    "running = True\n",
    "counter = 0\n",
    "error = False\n",
    "batch_num = 0\n",
    "\n",
    "for tweet_id in id_list:\n",
    "    counter += 1\n",
    "    try:\n",
    "        single_tweet_dict = retweets(tweet_id) # This collects a dictionary of 100 retweets associated with one original tweet\n",
    "        retweet_num = 1 # Next, it's going to go through each retweet in the dictionary and add it to the master dictionary\n",
    "        inner_running = True\n",
    "        while inner_running == True:\n",
    "            try:\n",
    "                master_tweet_dict[master_num] = single_tweet_dict[retweet_num]\n",
    "            except KeyError: # Not all tweets will have 100 retweets, so if it reaches the limit in the dictionary, it'll stop the loop.\n",
    "                master_num -= 1\n",
    "                inner_running = False\n",
    "            if inner_running == True:\n",
    "                retweet_num += 1\n",
    "                master_num += 1\n",
    "    except tw.TweepError: # This terminates the loop if TweepError raised and prints out the error code.\n",
    "        print(\"Error! Encountered error while trying to collect retweets from tweet number \" + str(counter))\n",
    "        try:\n",
    "            print(\"Error code is \" + str(tw.TweepError.response.text))\n",
    "        except:\n",
    "            print(\"Unknown error.\")\n",
    "        finally:\n",
    "            running = False\n",
    "            error = True\n",
    "    if counter == 75:\n",
    "        if running == True:\n",
    "            print(\"Just finished collecting the retweets of 75 original tweets. Going to pause for 15 minutes.\")\n",
    "            time.sleep(300) # pauses the program for 5 minutes after completing the 75th request to avoid exceeding the rate limits\n",
    "            print(\"Paused for 5 minutes so far. 10 minutes remaining.\")\n",
    "            time.sleep(300)\n",
    "            print(\"Paused for 10 minutes so far. 5 minutes remaining.\")\n",
    "            time.sleep(300)\n",
    "            counter = 0 # resets the counter to 0\n",
    "            batch_num +=1\n",
    "            print(\"Finished pausing for 15 minutes.\")\n",
    "        else:\n",
    "            print(\"Failed on the 75th request.\")\n",
    "    if running == False:\n",
    "        break\n",
    "            \n",
    "if error == False:\n",
    "    print(\"Finished all requests. The total number of tweets collected is\", batch_num*75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Printing to JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(name_json(username), 'w', encoding='utf8') as f:\n",
    "    json.dump(master_tweet_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Reading the JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(name_json(username), 'r') as g:\n",
    "    datastore = json.load(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'133598'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-cca6bcf1529c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatastore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'133598'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: '133598'"
     ]
    }
   ],
   "source": [
    "print(datastore['1']) # This is just to test everything went properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Saving just the Users to a .txt File as a List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished adding 133597 users to list using 186975 tweets.\n"
     ]
    }
   ],
   "source": [
    "user_num = 1\n",
    "users = []\n",
    "\n",
    "while user_num < len(id_list)*75:\n",
    "    try:\n",
    "        users.append(datastore[str(user_num)]['user']['screen_name'])\n",
    "        user_num += 1\n",
    "    except KeyError:\n",
    "        break\n",
    "\n",
    "print(\"Finished adding\", len(users), \"users to list using\", len(id_list)*75, \"tweets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open((str(username) + \"users.txt\"), 'w') as h:\n",
    "    print(users, file=h)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
